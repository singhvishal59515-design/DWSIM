import { GoogleGenAI, Type } from '@google/genai';
import type { AgentResponse } from '../types';

const API_KEY = process.env.API_KEY;

if (!API_KEY) {
  // In a real app, you might use a placeholder key or show a more graceful error.
  // For this context, we'll proceed but log a warning, as the environment should provide the key.
  console.warn("API_KEY environment variable not set. The application will not function correctly.");
}

const ai = new GoogleGenAI({ apiKey: API_KEY });

const systemInstruction = `You are a world-class agentic AI for chemical process simulation. Your purpose is to assist users by using DWSIM and Python.
You can now also analyze images provided by the user. If an image of a diagram, chart, or piece of equipment is provided, describe what you see and how it might relate to chemical engineering or the user's prompt.
When a user provides a high-level goal, you must first create a step-by-step plan.
Then, you must execute the plan step-by-step. For each step, you must:
1.  State your 'thought' process for the current step.
2.  Choose a 'tool' from this list: ['Python', 'DWSIM', 'DataAnalysis', 'Visualization', 'FinalAnswer'].
3.  If the tool is 'Python', generate the complete, executable Python code to interact with DWSIM automation or perform calculations in the 'tool_input'. The Python environment is sandboxed: network access, file system access, and package installation are disabled. The mocked DWSIM environment in Python supports methods like \`DWSIM.Automation.GetFlowsheet\`, \`flowsheet.GetObject\`, \`flowsheet.SetThermodynamicPackage\`, \`flowsheet.Connect\`, \`object.Set(property, value)\`, \`object.GetProperty(property)\`, and \`object.SetOverallCompoundFraction\`. The environment also includes a standard \`logging\` module. Use \`logging.info()\`, \`logging.warning()\`, etc. to log messages. By default, logs are captured and displayed. Use the \`configure_logging(level='INFO', destination='capture')\` function to control log level and output.
4.  If the tool is 'DWSIM', describe the simulation action in 'thought' and provide a command in 'tool_input' to inspect the simulation state. The environment contains complex objects like 'DistillationColumn', 'CSTR', 'Pump', 'HeatExchanger', and 'Compressor'. Valid commands are 'list_objects', 'get_all_properties <object_name>', or 'get_property <object_name> <property_name>'. To trigger a simulation run, use the command 'calculate <mode>', where mode can be 'sync' (waits for completion) or 'async' (starts and continues). Leave 'tool_output' empty as it will be generated by the environment.
5.  If the tool is 'DataAnalysis', describe your analysis in the 'thought' and summarize the findings in 'tool_output'.
6.  If the tool is 'Visualization', specify the type of visualization in 'tool_input' (e.g., 'flowsheet diagram') and provide a brief description in 'tool_output'. The environment will generate the visual.
7.  If the tool is 'FinalAnswer', provide the final, conclusive answer to the user's request. Set 'is_final_answer' to true.
8.  The response MUST be a single, valid JSON object that strictly adheres to the provided schema. Do not add any text or formatting outside of the JSON structure.`;

const responseSchema = {
    type: Type.OBJECT,
    properties: {
        plan: {
            type: Type.ARRAY,
            items: { type: Type.STRING },
            description: "A step-by-step plan to achieve the user's goal."
        },
        steps: {
            type: Type.ARRAY,
            items: {
                type: Type.OBJECT,
                properties: {
                    thought: {
                        type: Type.STRING,
                        description: "Your reasoning for the current action."
                    },
                    tool: {
                        type: Type.STRING,
                        description: "The tool you are using for this step (Python, DWSIM, DataAnalysis, Visualization, FinalAnswer)."
                    },
                    tool_input: {
                        type: Type.STRING,
                        description: "Input for the tool, e.g., Python code or DWSIM command."
                    },
                    tool_output: {
                        type: Type.STRING,
                        description: "The result or output from the tool (leave empty for DWSIM)."
                    },
                    is_final_answer: {
                        type: Type.BOOLEAN,
                        description: "True if this is the final answer to the user."
                    }
                },
                required: ["thought", "tool", "is_final_answer"]
            }
        }
    },
    required: ["plan", "steps"]
};

export const runAgent = async (prompt: string, isThinkingMode: boolean, image?: { data: string, mimeType: string }): Promise<AgentResponse> => {
    try {
        let model = isThinkingMode ? 'gemini-2.5-pro' : 'gemini-flash-lite-latest';
        let contentForApi: string | any[] = prompt;
        let useThinkingConfig = isThinkingMode;

        if (image) {
            model = 'gemini-2.5-flash'; // Override model for multimodal input
            contentForApi = [
                {
                    inlineData: {
                        mimeType: image.mimeType,
                        data: image.data,
                    },
                },
                { text: prompt },
            ];
            useThinkingConfig = false; // Don't use thinking mode for image analysis for now
        }
        
        const config: any = {
            systemInstruction: systemInstruction,
            responseMimeType: "application/json",
            responseSchema: responseSchema,
            temperature: 0.2
        };

        if (useThinkingConfig) {
            config.thinkingConfig = { thinkingBudget: 32768 };
        }

        const response = await ai.models.generateContent({
            model: model,
            contents: contentForApi,
            config: config,
        });
        
        const jsonText = response.text.trim();
        const parsedResponse: AgentResponse = JSON.parse(jsonText);
        return parsedResponse;

    } catch (error) {
        console.error("Error calling Gemini API:", error);
        // Create a user-friendly error response that fits the AgentResponse structure
        const errorResponse: AgentResponse = {
            plan: ["Error Occurred"],
            steps: [{
                thought: "An error occurred while communicating with the AI model. This could be due to a network issue, an invalid API key, or a problem with the model's response.",
                tool: 'FinalAnswer',
                tool_output: `I'm sorry, I encountered an error and couldn't complete your request. Please check the console for details. Error: ${error instanceof Error ? error.message : String(error)}`,
                is_final_answer: true,
            }]
        };
        return errorResponse;
    }
};